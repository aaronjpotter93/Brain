One idea that i have is to break the current convention of tasks related to projects. to instead be tasks related to projects but answers to content competency instead of a deadline. for example. you have an idea for an app. you define it and say i want to build this, and in that process of defining it you will undoubtedly be introducing scope creep. oh my gosh and this feature and that feature and... so on. But as that is a bad thing in deadline driven development (where reality is), its actually a good thing in (make believe land) competency driven development. this competency driven learning and development must have a system that can track in a satisfying and helpful way the logging of a person's time spent in different phases of learning and building: discovering new ideas, discovering holes in their understanding from prerequisite work, reinforcing relevant ideas. and all enabled by a system that is aware of their limits (owned by the individual-not their superiors as a way to punish or some weird big brother is watching shit), say they have their project and all its shinny features defined. in my experience, its overwhelmingly lopsided in the ratio between my current competency and concept dependencies to meet these requirements. I want a system that is ai enabled but doesn't take away from the person that glorious feeling of making a breakthrough, connecting ideas on their own and all the ai is doing is logging the whole thing to act as a guide to the developer what competencies they really do own, and can plan better around. so that when there are deadlines there could be a ratio, look there is all this that you need to learn and there is a complexity level of this much and in your past your learning rate is about this much so you could expect it to take this long to become competent in the thing you are needing to do, heres your deadline, and according to what you already are competent in, with a little spaced repetition, you could expect it to take this long... so here is my estimated completion time and you can expect it do be done by then. but this only works if there is a system that knows your limits intimately, and is also intimately aware of the content areas required to solve a problem. then hand the critical thinking and innovation over to the person while removing from them as much of the head banging against a wall experience as possible.

all of that to say. when you create a task. an ai model should assess your readiness to meet that task and also how specific and explicit is the task or is that task something that really demonstrates gaps in understanding/is identified as a higher level of abstraction, built on many other tasks they need to do which could be a combination of competent and not ready. and when that check gets ran, it creates a suggestions for how to move forward with the task. and instead of assigning a deadline for the task it actually just requires proof of competency for completion. so the task's true false check is fed to a function that involves the model who's aware of the context, the student, and the progress of their work (all of this should be defined by the user's intent, and if the system isn't satisfying to use then the guidance it provides to try and keep you "on track" should be changed and entirely within their right to do so. it feels icky at the thought of a superior using this system to "guide" the users back on track for their aims only because we live in a justice system built on merit, and in capitalism where competition drives higher wages is tied to better performance then the next guy.. this gets ugly. I want it to be a tool that only informs and guides at the user's whim. not the people who have power over them).

Learning and Engineering should feel rewarding and empowering, and i believe a system built on the future ai could offer humanity, should only complement the desires the individual has to create, to connect, to give, and to pioneer new frontiers. to enable us. it should not be used to control, coerce or intimidate us by some silly visionless entity.